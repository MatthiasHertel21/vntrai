# ğŸ§ª Sprint 18 Task Management Revolution - Manueller Testplan

**Datum:** 1. Juli 2025  
**Sprint:** 18 - Task Management Revolution  
**URL:** http://localhost:5004  
**Testumgebung:** Docker Container

## ğŸ“‹ **Ãœbersicht**

Dieser Testplan validiert die vollstÃ¤ndige Implementierung der Sprint 18 Features:
- Task-Definitionen in agent.json integriert
- Task-AusfÃ¼hrung in agentrun.json verwaltet  
- Tools "options" Field mit "assistant" Option
- Agent Task Editor in Agent Edit Page
- Sprint 18 API-Endpunkte

---

## ğŸ¯ **TEIL 1: AGENT TASK EDITOR TESTS**

### Test 1.1: Agent Creation & Basic UI
**Ziel:** Validierung der Agent-Erstellung und Task Editor Integration

**Schritte:**
1. ğŸŒ Navigiere zu `http://localhost:5004/agents`
2. âœ… ÃœberprÃ¼fe: Agents Overview lÃ¤dt korrekt
3. â• Klicke "Create Agent" oder "New Agent"
4. ğŸ“ FÃ¼lle aus:
   - Name: "Test Agent Sprint 18"
   - Category: "Testing"
   - Description: "Sprint 18 Task Management Test Agent"
5. ğŸ’¾ Speichere Agent
6. âœ… ÃœberprÃ¼fe: Agent wurde erfolgreich erstellt

**Erwartetes Ergebnis:**
- Agent wird in der Liste angezeigt
- Neue agent.json Datei wird unter `data/agents/` erstellt
- `tasks: []` Array ist vorhanden

---

### Test 1.2: Task Editor Integration
**Ziel:** Validierung des Task Editors in Agent Edit Page

**Schritte:**
1. ğŸ–±ï¸ Klicke "Edit" bei erstelltem Test Agent
2. âœ… ÃœberprÃ¼fe Layout:
   - Linke Spalte: Basic Information, **Task Editor**
   - Rechte Spalte: AI Assistant, Tasks, Files, etc.
3. ğŸ“‹ Lokalisiere "Task Editor" Container
4. âœ… ÃœberprÃ¼fe Elemente:
   - Header "Task Editor" 
   - "Add Task" Button mit "+" Icon
   - Leere Task-Liste (bei neuem Agent)

**Erwartetes Ergebnis:**
- Task Editor ist sichtbar und funktional
- UI-Layout entspricht Sprint 18 Spezifikation

---

### Test 1.3: AI Task Creation
**Ziel:** Erstellung einer AI Task Ã¼ber Task Editor

**Schritte:**
1. â• Klicke "Add Task" im Task Editor
2. ğŸ“ FÃ¼lle Task Details aus:
   - **Name:** "Content Generation Task"
   - **Type:** "AI" (auswÃ¤hlen)
   - **Description:** "Generate marketing content"
   - **Instructions:** "Create compelling marketing copy"
   - **Output Format:** "markdown"
3. â• FÃ¼ge Input Fields hinzu:
   - Field Name: "topic"
   - Field Type: "text" 
   - Field Label: "Content Topic"
   - Default Value: "AI Technology"
4. ğŸ’¾ Speichere Task
5. âœ… ÃœberprÃ¼fe: Task erscheint in Task Preview

**Erwartetes Ergebnis:**
- Task wird erfolgreich erstellt
- Task erscheint in "Tasks" Container (rechte Spalte)
- agent.json enthÃ¤lt Task-Definition im `tasks[]` Array

---

### Test 1.4: Tool Task Creation
**Ziel:** Erstellung einer Tool Task Ã¼ber Task Editor

**Schritte:**
1. â• Klicke "Add Task" im Task Editor
2. ğŸ“ FÃ¼lle Task Details aus:
   - **Name:** "API Integration Task"
   - **Type:** "Tool" (auswÃ¤hlen)
   - **Description:** "Execute API call via tool"
   - **Tool Selection:** [VerfÃ¼gbares Tool auswÃ¤hlen]
3. âš™ï¸ Konfiguriere Tool-spezifische Eingaben
4. ğŸ’¾ Speichere Task
5. âœ… ÃœberprÃ¼fe: Tool Task erscheint in Task Preview

**Erwartetes Ergebnis:**
- Tool Task wird erfolgreich erstellt
- Tool-Konfiguration wird korrekt gespeichert
- Task-Definition enthÃ¤lt tool_config Sektion

---

### Test 1.5: Task Management Operations
**Ziel:** Edit, Delete, Reorder Funktionen testen

**Schritte:**
1. ğŸ“ **Task Edit:**
   - Klicke "Edit" bei vorhandener Task
   - Ã„ndere Name und Description
   - Speichere Ã„nderungen
   - âœ… ÃœberprÃ¼fe: Ã„nderungen sind sichtbar

2. ğŸ”„ **Task Reorder:**
   - Nutze Drag & Drop oder Up/Down Buttons
   - Ã„ndere Reihenfolge der Tasks
   - âœ… ÃœberprÃ¼fe: Neue Reihenfolge wird beibehalten

3. ğŸ—‘ï¸ **Task Delete:**
   - Klicke "Delete" bei einer Task
   - BestÃ¤tige LÃ¶schung
   - âœ… ÃœberprÃ¼fe: Task wird entfernt

**Erwartetes Ergebnis:**
- Alle CRUD-Operationen funktionieren korrekt
- Ã„nderungen werden in agent.json persistiert
- UI aktualisiert sich in Echtzeit

---

## ğŸ› ï¸ **TEIL 2: TOOLS "OPTIONS" FIELD TESTS**

### Test 2.1: Tools Overview & Options
**Ziel:** Validierung des "options" Fields bei Tools

**Schritte:**
1. ğŸŒ Navigiere zu `http://localhost:5004/tools`
2. ğŸ” WÃ¤hle ein Tool aus (z.B. OpenAI-basiertes Tool)
3. âœï¸ Klicke "Edit" 
4. ğŸ“‹ Suche nach "Options" Sektion
5. âœ… ÃœberprÃ¼fe:
   - "Assistant" Option vorhanden
   - Checkbox fÃ¼r "Enable Assistant"
   - Assistant-Konfigurationsfelder

**Erwartetes Ergebnis:**
- Options Sektion ist sichtbar
- Assistant-Konfiguration verfÃ¼gbar
- Einstellungen sind speicherbar

---

### Test 2.2: Assistant Option Activation
**Ziel:** Aktivierung der Assistant Option fÃ¼r ein Tool

**Schritte:**
1. âœ… Aktiviere "Enable Assistant" Checkbox
2. ğŸ“ Konfiguriere Assistant Settings:
   - Model: "gpt-4-turbo-preview"
   - Instructions: "You are a helpful assistant for this tool"
   - Auto-Create: âœ… enabled
3. ğŸ’¾ Speichere Tool-Konfiguration
4. ğŸ”„ Lade Seite neu
5. âœ… ÃœberprÃ¼fe: Einstellungen bleiben erhalten

**Erwartetes Ergebnis:**
- Assistant Option wird aktiviert
- Konfiguration wird in tool.json gespeichert
- `options.assistant.enabled: true`

---

### Test 2.3: Agent Tool Selection Filter
**Ziel:** Nur Assistant-enabled Tools in Agent verfÃ¼gbar

**Schritte:**
1. ğŸ”™ ZurÃ¼ck zu Agent Edit Page
2. ğŸ¤– Gehe zur "AI Assistant" Sektion
3. ğŸ“‹ ÃœberprÃ¼fe Tool-Auswahl Dropdown
4. âœ… Validiere:
   - Nur Tools mit Assistant Option erscheinen
   - Nicht-Assistant Tools sind ausgeblendet
   - Tool-Liste ist gefiltert

**Erwartetes Ergebnis:**
- Tool-Filter funktioniert korrekt
- Nur Assistant-fÃ¤hige Tools verfÃ¼gbar
- UI zeigt korrekte Tools an

---

## ğŸš€ **TEIL 3: AGENTRUN TASK EXECUTION TESTS**

### Test 3.1: Agent Run Creation
**Ziel:** Erstellung eines Agent Runs mit Task States

**Schritte:**
1. ğŸ‘¤ Gehe zu Agent Detail Page
2. â–¶ï¸ Klicke "New Run" oder "Start Session"
3. ğŸ“ Benenne Agent Run: "Sprint 18 Test Run"
4. ğŸš€ Starte Agent Run
5. âœ… ÃœberprÃ¼fe:
   - Agent Run wird erstellt
   - Task States werden aus Agent Ã¼bernommen
   - Alle Tasks haben Status "pending"

**Erwartetes Ergebnis:**
- agentrun.json wird erstellt unter `data/agentrun/`
- `task_states[]` Array enthÃ¤lt alle Agent Tasks
- Initial Status: alle Tasks "pending"

---

### Test 3.2: Task Execution Interface
**Ziel:** Task-AusfÃ¼hrung Ã¼ber Agent Run UI

**Schritte:**
1. ğŸŒ Navigiere zu Agent Run Page
2. âœ… ÃœberprÃ¼fe Layout:
   - Linke Spalte: "Task Output"
   - Rechte Spalte: "Tasks", "Files", "Feedback"
3. ğŸ“‹ Lokalisiere Task-Liste in rechter Spalte
4. âœ… ÃœberprÃ¼fe Task-Anzeige:
   - Task Namen und Descriptions
   - Status Indicators (pending/running/completed)
   - "Execute" Buttons

**Erwartetes Ergebnis:**
- Agent Run UI lÃ¤dt korrekt
- Task-Definitionen werden aus Agent geladen
- Task-Status wird aus agentrun.json geladen

---

### Test 3.3: Task Execution Flow
**Ziel:** AusfÃ¼hrung einer Task mit Status-Updates

**Schritte:**
1. â–¶ï¸ Klicke "Execute" bei einer AI Task
2. ğŸ“ FÃ¼lle Input-Felder aus (falls vorhanden)
3. ğŸš€ Starte Task-AusfÃ¼hrung
4. â±ï¸ Beobachte Status-Ã„nderungen:
   - pending â†’ running â†’ completed/error
5. ğŸ“„ ÃœberprÃ¼fe Task Output im "Task Output" Bereich

**Erwartetes Ergebnis:**
- Task Status wird korrekt aktualisiert
- Inputs werden in agentrun.json gespeichert
- Results erscheinen im Output-Bereich
- execution_time wird berechnet

---

## ğŸŒ **TEIL 4: API ENDPUNKTE TESTS**

### Test 4.1: Sprint 18 Task Management API
**Ziel:** Validierung der neuen API Endpunkte

**API Tests Ã¼ber Browser Developer Tools oder Postman:**

```bash
# Agent Task Definitions
GET /api/task_management/agent/{agent_uuid}/tasks
POST /api/task_management/agent/{agent_uuid}/tasks
PUT /api/task_management/agent/{agent_uuid}/tasks/{task_uuid}
DELETE /api/task_management/agent/{agent_uuid}/tasks/{task_uuid}

# Agent Run Task Execution
GET /api/task_management/run/{run_uuid}/tasks
POST /api/task_management/run/{run_uuid}/tasks/{task_uuid}/execute
GET /api/task_management/run/{run_uuid}/tasks/{task_uuid}/status

# Tools Options API
GET /api/task_management/tools/{tool_id}/options
PUT /api/task_management/tools/{tool_id}/options
```

**Erwartetes Ergebnis:**
- Alle Endpunkte antworten mit korrekten HTTP Status Codes
- JSON Responses enthalten erwartete Datenstrukturen
- CSRF Protection funktioniert

---

## ğŸ§© **TEIL 5: INTEGRATION & MIGRATION TESTS**

### Test 5.1: Legacy Migration Support
**Ziel:** PrÃ¼fung der AbwÃ¤rtskompatibilitÃ¤t

**Schritte:**
1. ğŸ“ ÃœberprÃ¼fe bestehende Agent-Dateien (falls vorhanden)
2. ğŸ”„ Lade Agent in neuer Sprint 18 UI
3. âœ… Validiere:
   - Legacy Agents werden korrekt geladen
   - Migration-Warnungen erscheinen (falls nÃ¶tig)
   - Upgrade auf Sprint 18 Format mÃ¶glich

**Erwartetes Ergebnis:**
- Keine Breaking Changes fÃ¼r bestehende Daten
- Klare Migration-Pfade verfÃ¼gbar

---

### Test 5.2: Data Persistence Validation
**Ziel:** Validierung der Datenpersistierung

**Schritte:**
1. ğŸ“ Erstelle komplexe Task-Struktur
2. ğŸ”„ Stoppe Docker Container: `sudo docker-compose down`
3. ğŸš€ Starte Container neu: `sudo docker-compose up -d`
4. âœ… ÃœberprÃ¼fe:
   - Alle Tasks sind erhalten
   - Agent Run States sind korrekt
   - Keine Datenverluste

**Erwartetes Ergebnis:**
- VollstÃ¤ndige Datenpersistierung
- Keine Corruption nach Restart

---

## ğŸ“Š **TEIL 6: PERFORMANCE & FEHLERBEHANDLUNG**

### Test 6.1: Error Handling
**Ziel:** Robustheit bei Fehlereingaben

**Schritte:**
1. ğŸš« Versuche ungÃ¼ltige Task-Definitionen
2. âŒ Teste fehlerhafte API Calls
3. ğŸ”§ ÃœberprÃ¼fe Error Messages
4. ğŸ“ Validiere Rollback-Mechanismen

**Erwartetes Ergebnis:**
- Graceful Error Handling
- Benutzerfreundliche Fehlermeldungen
- Keine System-Crashes

---

### Test 6.2: UI Responsiveness
**Ziel:** Performance der neuen UI-Komponenten

**Schritte:**
1. ğŸ“± Teste auf verschiedenen BildschirmgrÃ¶ÃŸen
2. âš¡ ÃœberprÃ¼fe Ladezeiten
3. ğŸ–±ï¸ Teste InteraktivitÃ¤t (Drag & Drop, etc.)
4. ğŸ“Š Validiere mit vielen Tasks (10+ Tasks)

**Erwartetes Ergebnis:**
- Responsive Design funktioniert
- Keine Performance-Probleme
- Smooth User Experience

---

## âœ… **ABNAHMEKRITERIEN - SPRINT 18 DEFINITION OF DONE**

Nach Abschluss aller Tests mÃ¼ssen folgende Kriterien erfÃ¼llt sein:

- [ ] **Task-Editor vollstÃ¤ndig in Agent Edit Page integriert**
- [ ] **Task-Definitionen werden in agent.json gespeichert**  
- [ ] **AgentRun UI verwaltet Task-AusfÃ¼hrung und -Results**
- [ ] **Keine eigenstÃ¤ndigen Task-CRUD-Operationen mehr**
- [ ] **Task-Status wird in agentrun.json verwaltet**
- [ ] **Tools "options" Feld mit "assistant" Option implementiert**
- [ ] **Sprint 18 API-Endpunkte funktionieren**
- [ ] **Data Manager erweitert mit Sprint 18 Methoden**
- [ ] **Legacy API als deprecated markiert**

---

## ğŸ“ **TESTPROTOKOLL**

**Tester:** _________________  
**Datum:** _________________  
**Version:** Sprint 18  

### Testergebnisse:
- [ ] Teil 1: Agent Task Editor - âœ… Bestanden / âŒ Fehlgeschlagen
- [ ] Teil 2: Tools Options Field - âœ… Bestanden / âŒ Fehlgeschlagen  
- [ ] Teil 3: AgentRun Task Execution - âœ… Bestanden / âŒ Fehlgeschlagen
- [ ] Teil 4: API Endpunkte - âœ… Bestanden / âŒ Fehlgeschlagen
- [ ] Teil 5: Integration & Migration - âœ… Bestanden / âŒ Fehlgeschlagen
- [ ] Teil 6: Performance & Error Handling - âœ… Bestanden / âŒ Fehlgeschlagen

### Gefundene Issues:
1. ________________________________
2. ________________________________
3. ________________________________

### Empfehlungen:
_________________________________________________
_________________________________________________

**Gesamtbewertung:** âœ… Sprint 18 Ready fÃ¼r Production / âŒ Weitere Entwicklung erforderlich

---

## ğŸ¯ **NÃ„CHSTE SCHRITTE**

Nach erfolgreichem Abschluss der Tests:

1. **Sprint 18 als abgeschlossen markieren**
2. **Documentation Update in development.md**
3. **Sprint 18 nach closed_sprints.md verschieben**
4. **Sprint 19 "Agent Run Revolution" vorbereiten**

---

**Hinweis:** Dieser Testplan deckt alle kritischen Sprint 18 Features ab. Bei Problemen siehe Debug-Logs im Docker Container: `sudo docker logs age_web_1`
